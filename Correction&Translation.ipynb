{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!export LC_ALL=en_US.UTF-8\n",
        "!export LC_CTYPE=en_US.UTF-8"
      ],
      "metadata": {
        "id": "UimnM5LhoE8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google_play_scraper\n",
        "!pip install transformers --no-cache-dir\n",
        "!pip install --upgrade transformers\n",
        "!pip uninstall sentencepiece -y\n",
        "!pip install sentencepiece --no-cache-dir\n",
        "!pip install pydrive\n",
        "!python -m spacy download fr_core_news_sm\n",
        "!pip install pyspellchecker\n",
        "!pip install language-tool-python\n",
        "!pip install autocorrect\n",
        "#!pip list --outdated\n",
        "!pip install sacremoses\n",
        "!pip install nltk\n"
      ],
      "metadata": {
        "id": "AMCZiw5bi_70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google_play_scraper import Sort, reviews_all\n",
        "from multiprocessing import Pool\n",
        "import csv\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from transformers import pipeline, TranslationPipeline, AutoTokenizer, AutoModelForSeq2SeqLM, MarianMTModel, MarianTokenizer\n",
        "import re\n",
        "import time\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from tqdm import tqdm\n",
        "import spacy\n",
        "import language_tool_python"
      ],
      "metadata": {
        "id": "OHv_-h_3-oX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from autocorrect import Speller\n",
        "from textblob import TextBlob\n",
        "from language_tool_python import LanguageTool\n",
        "import time\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Instancier les correcteurs\n",
        "spell_checker = Speller(lang='fr')\n",
        "blob = TextBlob('fr')\n",
        "tool = LanguageTool('fr')\n",
        "\n",
        "# La phrase √† tester\n",
        "sentence = \"Tout ait tr√®s bien me prot√®ge jamais eu de probl√®mes, tous anticouvid, tracing, √†\"\n",
        "\n",
        "# Tokeniser la phrase\n",
        "tokens = word_tokenize(sentence)\n",
        "\n",
        "# Correction orthographique\n",
        "start_time = time.time()\n",
        "corrected_spell = [spell_checker(token) for token in tokens]\n",
        "end_time = time.time()\n",
        "print(\"Correction orthographique: \", \" \".join(corrected_spell))\n",
        "print(f\"Temps de correction (SpellChecker): {end_time - start_time:.4f} secondes\\n\")\n",
        "\n",
        "# Correction grammaticale\n",
        "start_time = time.time()\n",
        "blob = TextBlob(sentence)\n",
        "corrected_grammar = str(blob.correct())\n",
        "end_time = time.time()\n",
        "print(\"Correction grammaticale: \", corrected_grammar)\n",
        "print(f\"Temps de correction (TextBlob): {end_time - start_time:.4f} secondes\\n\")\n",
        "\n",
        "# Correction de style\n",
        "start_time = time.time()\n",
        "corrected_style = tool.correct(sentence)\n",
        "end_time = time.time()\n",
        "print(\"Correction de style: \", corrected_style)\n",
        "print(f\"Temps de correction (LanguageTool): {end_time - start_time:.4f} secondes\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "pcXVECu-QeN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifiant de l'application sur le Google Play Store\n",
        "app_id = 'fr.gouv.android.stopcovid'\n",
        "\n",
        "# Extraire tous les avis de l'application\n",
        "reviews = reviews_all(\n",
        "    app_id=app_id,\n",
        "    lang='fr',  # Langue des avis\n",
        "    sort=Sort.NEWEST,  # Ordonner les avis par date de publication (plus r√©cents d'abord)\n",
        ")\n",
        "\n",
        "print (reviews[0:10])"
      ],
      "metadata": {
        "id": "mW9hRAVAnSYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "045d62d2-38db-43a9-f04e-0cb71eaeba8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'reviewId': '02ff027b-65c1-453a-9d01-00ebfceace17', 'userName': 'blondy pop', 'userImage': 'https://play-lh.googleusercontent.com/a-/ACB-R5SBhQoIdIYwumonJxeIi31XZ3V3zeiQAtWTHK_G', 'content': \"En th√©orie c'est pas mal mais c'est super malin de pas avoir mis de syst√®me de sauvegarde des document\", 'score': 1, 'thumbsUpCount': 0, 'reviewCreatedVersion': '5.5.0', 'at': datetime.datetime(2023, 3, 16, 8, 50, 15), 'replyContent': None, 'repliedAt': None}, {'reviewId': '0c06255a-a53a-458c-a2f5-72ee82f2d4a3', 'userName': 'Jean-Luc Dancoine', 'userImage': 'https://play-lh.googleusercontent.com/a-/ACB-R5TGK-P_MnSxJQxUJf7eLNLEF3aiP1vlXFt7j9h8SA', 'content': 'Tr√®s barbant,ces enqu√™tes, mais je le fait de bon c≈ìur', 'score': 5, 'thumbsUpCount': 0, 'reviewCreatedVersion': '5.5.0', 'at': datetime.datetime(2023, 3, 15, 18, 56, 31), 'replyContent': None, 'repliedAt': None}, {'reviewId': '6e16df96-55f1-4099-8e97-8e078a06e55e', 'userName': 'Fabrice Blay', 'userImage': 'https://play-lh.googleusercontent.com/a-/ACB-R5SJLhPpRIWEnCpWVU8MOykCcOpAh3ujl2Djbj0G', 'content': 'Super utile mais peu demand√©', 'score': 5, 'thumbsUpCount': 0, 'reviewCreatedVersion': None, 'at': datetime.datetime(2023, 3, 15, 15, 10, 42), 'replyContent': None, 'repliedAt': None}, {'reviewId': '9ffe5abc-bbc3-486a-8df4-681eeecd1b0c', 'userName': 'CLAUDE GRANDSIRE', 'userImage': 'https://play-lh.googleusercontent.com/a/AGNmyxZCuk1mBtihKoChRQK1gd-C5F2uxymv-VYk4D43=mo', 'content': 'Inbb', 'score': 4, 'thumbsUpCount': 0, 'reviewCreatedVersion': '4.4.0', 'at': datetime.datetime(2023, 3, 15, 13, 17, 57), 'replyContent': None, 'repliedAt': None}, {'reviewId': 'e718696a-e578-460a-b1f3-80282052fce1', 'userName': 'Axle Moonshine', 'userImage': 'https://play-lh.googleusercontent.com/a/AGNmyxaTh2pVU8lxfle7XcbKI_OBP2RobmxIN6-z9hHL=mo', 'content': 'Consomme/g√©n√®re al√©atoirement plus de 200Mo de donn√©es (hors application) sur la m√©moire de stockage interne, pour trois certificats √ßa fait beaucoup. Surtout quand le t√©l√©phone date un peu et que syst√®me, plus mises √† jour, plus logiciels obligatoires (Google/surcouche constructeur/op√©rateur) laissent moins de 2Go pour les applications n√©cessaires/utiles... Cod√© avec des moufles ???', 'score': 1, 'thumbsUpCount': 2, 'reviewCreatedVersion': None, 'at': datetime.datetime(2023, 3, 15, 2, 29, 47), 'replyContent': None, 'repliedAt': None}, {'reviewId': 'da383288-cbd7-45f9-9736-6213d5a8b5b9', 'userName': 'Charlotte 2V', 'userImage': 'https://play-lh.googleusercontent.com/a/AGNmyxYqc1p05LEFgpVU6_J9Peon8qWID281z791tLMQ=mo', 'content': \"J'ai √©t√© oblig√© d'installer cette application, je ne peux donc pas avoir un avis favorable\", 'score': 1, 'thumbsUpCount': 0, 'reviewCreatedVersion': '5.4.0', 'at': datetime.datetime(2023, 3, 14, 20, 40, 43), 'replyContent': None, 'repliedAt': None}, {'reviewId': '471a31bd-a74f-4934-b31d-796bba335a17', 'userName': 'Anthony Smith', 'userImage': 'https://play-lh.googleusercontent.com/a-/ACB-R5TgiolwnnIA_xwlW5XHz-H3dZlaY_dRuUmAFukXXg', 'content': \"L'appli des collabos 2.0\", 'score': 1, 'thumbsUpCount': 0, 'reviewCreatedVersion': None, 'at': datetime.datetime(2023, 3, 14, 9, 40), 'replyContent': None, 'repliedAt': None}, {'reviewId': '3edbd0ba-4623-4db6-8031-1f607a17a22d', 'userName': 'Matt wolf', 'userImage': 'https://play-lh.googleusercontent.com/a/AGNmyxbPHedVWywydROoWnKSR9MpxScKUPasRe4P5biT=mo', 'content': 'Du flicage !', 'score': 1, 'thumbsUpCount': 0, 'reviewCreatedVersion': None, 'at': datetime.datetime(2023, 3, 14, 0, 8, 48), 'replyContent': None, 'repliedAt': None}, {'reviewId': 'e2322b25-b6ec-45da-af0f-e7b3d927bade', 'userName': 'MARCK-O DE MEULEMEESTER (EL LOCO)', 'userImage': 'https://play-lh.googleusercontent.com/a-/ACB-R5TXDWvU-Ici7F4527pVC1dsRGo689D0DlBwjF8J53I', 'content': 'Bien ait ken il fau √† note toure de montrais qu\\'onez-pas d√®s B≈ìffeüêÇ ait ni d√®s Moutonüêëou moutonnes(Mi2\"OB√âLIJJ\") üêîCOKORIZCAUTüêìCAUT-CAUT-CAUTüèÅ BüòâN APP√âTIT, \"bien s√ªr\", MESDAMES, MESSIEURS et Toi et l\\'autre √† t√©co pile!...', 'score': 5, 'thumbsUpCount': 0, 'reviewCreatedVersion': '4.0.3', 'at': datetime.datetime(2023, 3, 12, 11, 37, 44), 'replyContent': None, 'repliedAt': None}, {'reviewId': 'a8ab3ff5-7665-4b2a-a8aa-90dd8236d7fe', 'userName': 'Jean Pierre Gautier', 'userImage': 'https://play-lh.googleusercontent.com/a/AGNmyxYahXe16nJ1wp7RaLQ6Me0TpQHErxMkvIs9zOgH=mo', 'content': \"56566 jours 'y5\", 'score': 3, 'thumbsUpCount': 0, 'reviewCreatedVersion': '4.3.0', 'at': datetime.datetime(2023, 3, 11, 15, 32, 26), 'replyContent': None, 'repliedAt': None}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trier les commentaires par nombre de likes\n",
        "reviews_sorted = sorted(reviews, key=lambda x: x['thumbsUpCount'], reverse=True)\n",
        "\n",
        "print(reviews_sorted[0:2000])"
      ],
      "metadata": {
        "id": "sneRrn-YLZS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed"
      ],
      "metadata": {
        "id": "LFVUnj3GC8pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pre-process, correction, translation, export\n",
        "from language_tool_python import LanguageTool\n",
        "import nltk\n",
        "import numpy as np\n",
        "import concurrent.futures\n",
        "import itertools\n",
        "import torch\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def grouper(iterable, n):\n",
        "    args = [iter(iterable)] * n\n",
        "    return itertools.zip_longest(*args, fillvalue=None)\n",
        "\n",
        "# Load the LanguageTool model\n",
        "tool = LanguageTool('fr')\n",
        "\n",
        "# Fonction pour pr√©traiter et corriger les commentaires avant la traduction\n",
        "def preprocess_batch(comments):\n",
        "    # Remove HTML tags\n",
        "    comments = [re.sub('<[^<]+?>', '', comment) for comment in comments]\n",
        "    # Remove links\n",
        "    comments = [re.sub(r'http\\S+', '', comment) for comment in comments]\n",
        "    # Remove useless special characters (emojis, etc.)\n",
        "    comments = [re.sub('[^A-Za-z0-9\\s\\.\\'\\?,!]+', '', comment) for comment in comments]\n",
        "    # Normalize text\n",
        "    comments = [re.sub(r\"(\\w+)'\\s*(\\w+)\", r\"\\1\\2\", comment) for comment in comments]\n",
        "    # Convert to lowercase\n",
        "    # comments = [''.join(c.lower() for c in comment) for comment in comments]\n",
        "    # Add spaces after punctuation marks\n",
        "    comments = [re.sub(r\"([a-zA-Z])([.,;:!?)])\", r\"\\1 \\2\", comment) for comment in comments] \n",
        "    \n",
        "    # Correct spelling and grammar\n",
        "    def correct_batch(batch):\n",
        "        return [tool.correct(comment) for comment in batch]\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        corrected_comments = []\n",
        "        batches = grouper(comments, batch_size)\n",
        "        futures = []\n",
        "        for batch in batches:\n",
        "            batch = [comment for comment in batch if comment is not None]\n",
        "            futures.append(executor.submit(correct_batch, batch))\n",
        "        for future in as_completed(futures):\n",
        "            corrected_comments.extend(future.result())\n",
        "\n",
        "    corrected_comments_filtered = []\n",
        "    for i in range(len(corrected_comments)):\n",
        "        corrected = corrected_comments[i]\n",
        "        if corrected and len(corrected) >= 10 and len(corrected) <= 5000:\n",
        "            corrected_comments_filtered.append(corrected)\n",
        "        else:\n",
        "            corrected_comments_filtered.append(\"\")\n",
        "    return corrected_comments_filtered\n",
        "\n",
        "\n",
        "# load the model and tokenizer for translation \n",
        "model_name = \"Helsinki-NLP/opus-mt-ROMANCE-en\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name).to('cuda')\n",
        "\n",
        "#Set up the translation pipeline\n",
        "translator = TranslationPipeline(model=model, tokenizer=tokenizer, task=\"translation_fr_to_en\")\n",
        "\n",
        "# Translate the comments in parallel using threads and batches\n",
        "def translate_batch(batch):\n",
        "    with torch.no_grad():  # we don't need to compute gradients during inference\n",
        "        input_ids = tokenizer.batch_encode_plus(batch, return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to('cuda')\n",
        "        outputs = model.generate(input_ids)\n",
        "        decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "        return decoded_outputs\n",
        "\n",
        "def translate_comments(preprocessed_comments, batch_size=32):\n",
        "    translated_comments = []\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        batches = grouper(preprocessed_comments, batch_size)\n",
        "        futures = []\n",
        "        for batch in batches:\n",
        "            batch = [comment for comment in batch if comment is not None]\n",
        "            futures.append(executor.submit(translate_batch, batch))\n",
        "        for future in as_completed(futures):\n",
        "            translated_comments.extend(future.result())\n",
        "    return translated_comments\n",
        "\n",
        "# Select the first 20000/60000 reviews\n",
        "selectedreviews = reviews_sorted[0:10000]\n",
        "selectedcomments = [review['content'] for review in selectedreviews]\n",
        "\n",
        "# Split the comments into batches\n",
        "batch_size = 32\n",
        "comment_batches = [selectedcomments[i:i+batch_size] for i in range(0, len(selectedcomments), batch_size)]\n",
        "\n",
        "# Preprocess the comments before translation\n",
        "preprocessed_comments = []\n",
        "for review_batch in tqdm(comment_batches, desc=\"Preprocessing in progress\"):\n",
        "    batch_preprocessed = preprocess_batch(review_batch)\n",
        "    preprocessed_comments.extend(batch_preprocessed)\n",
        "    \n",
        "\n",
        "# Lib√©ration de la m√©moire GPU\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "def associate_comments(preprocessed_comments, translated_comments):\n",
        "    translated_comments_dict = {}\n",
        "    for i in range(len(preprocessed_comments)):\n",
        "        preprocessed_comment = preprocessed_comments[i]\n",
        "        if preprocessed_comment is not None and i < len(translated_comments):\n",
        "            translated_comments_dict[preprocessed_comment] = translated_comments[i]\n",
        "    return translated_comments_dict\n",
        "\n",
        "# Split the preprocessed comments into batches\n",
        "preprocessed_batches = [preprocessed_comments[i:i+batch_size] for i in range(0, len(preprocessed_comments), batch_size)]\n",
        "#translate the comments\n",
        "translated_comments = []\n",
        "for batch in tqdm(preprocessed_batches, desc=\"Translation in progress\"):\n",
        "    batch_translations = translate_comments(batch)\n",
        "    translated_comments.extend(batch_translations)\n",
        "\n",
        "# Lib√©ration de la m√©moire GPU\n",
        "torch.cuda.empty_cache()\n",
        "# remove punctuation for csv format and future NLP\n",
        "preprocessed_comments = [re.sub(r'[^\\w\\s]', '', comment) for comment in preprocessed_comments]\n",
        "translated_comments = [re.sub(r'[^\\w\\s]', '', comment) for comment in translated_comments]\n",
        "print(preprocessed_comments)\n",
        "print(translated_comments)\n",
        "# Associate the translated comments with the original comments in a dictionary\n",
        "translated_comments_dict = associate_comments(preprocessed_comments, translated_comments)\n",
        "# Define a function to export the data\n",
        "def export_data_to_csv(reviews, preprocessed_comments, translated_comments_dict, filename, batch_size=16):\n",
        "    # Remove existing file if it exists\n",
        "    if os.path.exists(filename):\n",
        "        os.remove(filename)\n",
        "    # Create a DataFrame with the reviews data\n",
        "    df = pd.DataFrame(reviews)\n",
        "    # Rename the 'content' column to 'original_comment'\n",
        "    df = df.rename(columns={'content': 'original_comment'})\n",
        "    # Add a column with the preprocessed comments\n",
        "    df['preprocessed_comment'] = [comment for comment in preprocessed_comments]\n",
        "    # Add a column with the translated comments\n",
        "    df['translated_comment'] = [translated_comments_dict.get(comment, \"\") for comment in df['preprocessed_comment']]\n",
        "    # Drop unnecessary columns\n",
        "    df = df.drop(['userImage', 'reviewCreatedVersion', 'replyContent', 'repliedAt', 'original_comment'], axis=1)\n",
        "    # Define a function to process each batch in parallel\n",
        "    def process_batch(start, end):\n",
        "        batch_df = df[start:end]\n",
        "        batch_df.to_csv(filename, mode='a', index=False, header=(start == 0)) #put mode=\"a\" and not \"w\" otherwise each batch of 32 will write on the other and the exported file will be size of the last batch everytime\n",
        "\n",
        "    # Process the data in parallel using threads and batches\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        futures = []\n",
        "        for i in range(0, len(df), batch_size):\n",
        "            futures.append(executor.submit(process_batch, i, i+batch_size))\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            future.result()\n",
        "\n",
        "# Call the function to export the data\n",
        "export_data_to_csv(selectedreviews, preprocessed_comments, translated_comments_dict, 'translated_reviews.csv', batch_size=32)\n",
        "\n",
        "print(\"The reviews have been successfully exported to the CSV file.\")\n",
        "\n",
        "df = pd.read_csv(\"translated_reviews.csv\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CZlOrUGf12P",
        "outputId": "ba890f6b-d75a-443f-af4e-251b94cbfa72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocessing in progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [27:05<00:00,  5.19s/it]\n",
            "Translation in progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [41:45<00:00,  8.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The reviews have been successfully exported to the CSV file.\n",
            "                               reviewId          userName  score  \\\n",
            "0  e1aeca72-bec3-4c26-a170-9fe49b8c7d9d  Corentin Prigent      5   \n",
            "1  388a0e9e-d7a3-4f19-b792-2df821b6da3f   claude leclercq      3   \n",
            "2  46463794-2169-4191-b3f2-136f7ade6760     Timoth√©e Brun      5   \n",
            "3  2d4a1f11-652e-4442-8629-7f56ad511240    Olivier FEBWIN      4   \n",
            "4  8eeb4d02-2b8e-422c-93d8-3ef125239e50     Baptiste Piat      4   \n",
            "\n",
            "   thumbsUpCount                   at  \\\n",
            "0           3387  2022-02-13 05:56:53   \n",
            "1           2511  2021-04-06 06:40:05   \n",
            "2           1829  2022-01-02 08:43:48   \n",
            "3           1692  2022-10-12 09:51:39   \n",
            "4           1658  2022-01-28 21:54:09   \n",
            "\n",
            "                                preprocessed_comment  \\\n",
            "0  App excellente pas de pub dure de vie assez lo...   \n",
            "1  Premier avantage imm√©diatement visible plus be...   \n",
            "2  Ces jeux est g√©nial il y a plein de possibilit...   \n",
            "3  Pourquoi obliger lactivation de toutes les not...   \n",
            "4  Un peu perdu dans ce monde ouvert vraiment vas...   \n",
            "\n",
            "                                  translated_comment  \n",
            "0  Excellent app no advertising quite long lifesp...  \n",
            "1  The first immediately visible advantage plus t...  \n",
            "2  These games are great there are plenty of poss...  \n",
            "3  Why require all notifications to be activated ...  \n",
            "4  A little lost in this really vast open world A...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lib√©ration de la m√©moire GPU\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "AaHGf8ZFnnds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connexion √† Google Drive\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Recherche du dossier dans lequel copier le fichier CSV\n",
        "folder_name = 'TOUSANTICOVID'\n",
        "folder_list = drive.ListFile({'q': \"mimeType='application/vnd.google-apps.folder' and trashed=false and title='\" + folder_name + \"'\"}).GetList()\n",
        "if len(folder_list) > 0:\n",
        "    folder = folder_list[0]\n",
        "else:\n",
        "    folder = drive.CreateFile({'title': folder_name, 'mimeType': 'application/vnd.google-apps.folder'})\n",
        "    folder.Upload()\n",
        "    \n",
        "# Upload du fichier CSV dans le dossier\n",
        "file = drive.CreateFile({'title': 'translated_reviews.csv', 'parents': [{'id': folder['id']}]})\n",
        "file.SetContentFile('translated_reviews.csv') #assurez-vous √©galement que le fichier CSV sur le Drive est correctement t√©l√©charg√© en utilisant la m√©thode SetContentFile() avant de t√©l√©charger le fichier avec la m√©thode Upload()\n",
        "file.Upload()\n",
        "\n",
        "# Ouvrir le fichier sur le Drive pour v√©rifier que les donn√©es ont bien √©t√© copi√©es\n",
        "file = drive.CreateFile({'id': file['id']})\n",
        "content = file.GetContentString()\n",
        "print(\"Le fichier CSV sur le Drive contient:\\n\", content)"
      ],
      "metadata": {
        "id": "6Nyrul33h7M0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8b7ce2c-a01e-46b2-85e2-2bc3de1df54c"
      },
      "execution_count": null,
      "outputs": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3bXcV8NOvs9X",
        "outputId": "fccca498-a229-4cdd-b92f-c9e770ca1825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}
